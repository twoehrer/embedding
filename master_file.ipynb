{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined File\n",
    "\n",
    "This file should combine all the other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "num_hidden = 6 # number of hidden layers. The total network has additionl 2 layers: input to hidden and hidden to output\n",
    "input_dim = 2\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "activation = 'tanh' #'relu' and 'tanh' are supported\n",
    "\n",
    "# Training Params\n",
    "load_file = None\n",
    "cross_entropy = True #True supported with binary classification only\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.training\n",
    "from models.training import make_circles_uniform\n",
    "\n",
    "# Generate training data\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = np.random.randint(1000)\n",
    "# seed = 163\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "#footnnote to display on plots to make sure that plots and model/trainign params do not get confused\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "n_points = 2000 #number of points in the dataset\n",
    "\n",
    "inner_radius = 0.5\n",
    "outer_radius = 1\n",
    "buffer = 0.2\n",
    "\n",
    "import importlib\n",
    "importlib.reload(models.training) # Reload the module\n",
    "\n",
    "train_loader, test_loader = make_circles_uniform(output_dim = 1, n_samples = n_points, inner_radius = 0.5, outer_radius = 1.0, buffer = 0.1, cross_entropy=cross_entropy, seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, label in train_loader:\n",
    "    print(input[:5], label[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload models.resnet module after changes without restarting the kernel\n",
    "import importlib\n",
    "import models.resnets\n",
    "import models.training\n",
    "importlib.reload(models.resnets) # Reload the module\n",
    "importlib.reload(models.training) # Reload the module\n",
    "from models.resnets import ResNet\n",
    "from models.training import compute_accuracy, train_model, train_until_threshold, plot_loss_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant width 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train models\n",
    "model_base, acc_base, losses_base = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_base, title=f\"Base Model Loss Curve\", filename = 'ff6hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import plots.plots \n",
    "from plots.plots import plot_decision_boundary, plot_level_sets\n",
    "importlib.reload(plots.plots) # Reload the module\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_base, X_test, y_test, show=True, file_name= 'ff6hiddencirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_base, show=True, file_name= 'ff6hiddencirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented model: width 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 3\n",
    "num_hidden = 1\n",
    "\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "seed = 288\n",
    "\n",
    "model_aug, acc_aug, losses_aug = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95, seed=seed,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_aug, title=f\"Augmented Model Loss Curve\", filename = 'ff6hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "plot_decision_boundary(model_aug, X_test, y_test, show=True, file_name= 'ffaugcirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_aug, show=True, file_name= 'ffaugcirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_param = 1 # this sets model from feed forward to residual network\n",
    "\n",
    "num_hidden = 6\n",
    "hidden_dim = 2\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "model_res, acc_res, losses_res = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=skip_param, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_res, title=f\"ResNet Model Loss Curve\", filename = 'ff6_res')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_res, X_test, y_test, show=True, file_name= 'ff6resnetcirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_res, show=True, file_name= 'ff6resnetcirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "num_epochs = 100\n",
    "\n",
    "skip_values = np.linspace(0, 5, 6)  # e.g., [0.0, 0.125, ..., 1.0]\n",
    "# skip_values = [0, 0, 0 , 0 , 0]  # e.g., [0.0, 0.125, ..., 1.0]\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(skip_values) / n_cols))\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(3.5 * n_cols, 4 * n_rows), facecolor='white', dpi = 900)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.) \n",
    "# num_epochs = 10\n",
    "for idx, skip in enumerate(skip_values):\n",
    "    print(f\"Training model with skip_param = {skip:.2f}\")\n",
    "    \n",
    "    seed = 163\n",
    "    print(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    model = ResNet(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim,\n",
    "                   num_hidden=num_hidden, skip_param=skip, activation=activation)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.BCEWithLogitsLoss() if cross_entropy else nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    ax = axes.flatten()[idx]\n",
    "    plot_decision_boundary(model, X_test, y_test, title=f\"Skip: {skip:.2f}\", ax=ax, show=False, colorbar=False, show_points=False, amount_levels=100)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.axis('tight')\n",
    "    ax.set_aspect('equal') \n",
    "    \n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(skip_values), len(axes.flatten())):\n",
    "    fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "fig.suptitle(f\"ResNets with amount layers = {num_hidden + 2} and different weights of shortcut\", fontsize=16)\n",
    "\n",
    "# ðŸ’¡ Leave room at top for the title\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "plt.savefig('ff6hidden_skip_params.png', dpi=900, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular value computations and plotting\n",
    "We want to determine singular points in the compact space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid over the input space.\n",
    "grid_size = 200 # Adjust as needed.\n",
    "\n",
    "importlib.reload(plots.plots) # Reload the module\n",
    "from plots.plots import psi_manual, model_to_func, sv_plot\n",
    "\n",
    "# def psi_manual(x, func):\n",
    "#     \"\"\"\n",
    "#     x: a tensor of shape (2,) representing a point in R^2.\n",
    "#     model: a function mapping R^2 to R^output_dim.\n",
    "    \n",
    "#     Returns:\n",
    "#       The smallest singular value of the Jacobian of model at x.\n",
    "#     \"\"\"\n",
    "#     # Ensure x is a leaf variable with gradient tracking enabled.\n",
    "#     x = x.clone().detach().requires_grad_(True)  \n",
    "#     # print(f\"x shape: {x.shape}\")  # Debugging line to check the shape of x\n",
    "    \n",
    "    \n",
    "#     # Compute the Jacobian using torch.autograd.functional.jacobian (compatible with Python 3.8)\n",
    "#     jacobian = torch.autograd.functional.jacobian(func, x, create_graph=True)\n",
    "#     # print(f\"Jacobian shape: {jacobian.shape}\")  # Debugging line to check the shape of the Jacobian\n",
    "#     jacobian = jacobian  # Remove the artificial batch dimension\n",
    "#     # print(f\"Jacobian shape after squeeze: {jacobian.shape}\")  # Debugging line to check the shape after squeeze\n",
    "#     # Compute singular values using svdvals (available in PyTorch 1.8, compatible with Python 3.8)\n",
    "#     singular_values = torch.svd(jacobian, compute_uv=False)[1] #svd interprets here the jacobian as a SQUARE matrix of the largest dimension, hence it \n",
    "    \n",
    "   \n",
    "#     return singular_values.detach().numpy()\n",
    "  \n",
    "\n",
    "# def model_to_func(model,from_layer=0, to_layer=-1):\n",
    "  \n",
    "#   if from_layer == 0 and to_layer == -1: # this is the case for input to last hidden layer (without output layer)\n",
    "#     func = lambda inp: model(inp.unsqueeze(0), output_layer = False).squeeze(0)  # Add artificial batch dimension which is needed because of batch normalization layer BatchNorm1d and remove it again from the model output.\n",
    "#   else: \n",
    "#     func = lambda inp: model.sub_model(inp.unsqueeze(0), from_layer=from_layer, to_layer = to_layer).squeeze(0)\n",
    "  \n",
    "#   return func\n",
    "  \n",
    "\n",
    "# def sv_plot(func, sv_index = 0, x_range = [-1,1], y_range = [-1,1], grid_size = 100, ax = None, title = ''):\n",
    "#   x_values = np.linspace(x_range[0], x_range[1], grid_size)\n",
    "#   y_values = np.linspace(y_range[0], y_range[1], grid_size)\n",
    "#   psi_values = np.zeros((grid_size, grid_size, 2))\n",
    "  \n",
    "#   # Evaluate psi(x) over the grid.\n",
    "#   for i, xv in enumerate(x_values):\n",
    "#       for j, yv in enumerate(y_values):\n",
    "#           # Create a 2D point as a torch tensor.\n",
    "#           x_point = torch.tensor([xv, yv], dtype=torch.float32)\n",
    "#           psi_values[j, i,:] = psi_manual(x_point, func) #one subtlety here: if there is only one SV it gets broadcast to all dimensions of psi_values[j,i,:] in the last dimension. this reduces if statements for e.g. the last layer, but we need to notice that the SINGLE SV gets plotted twice  \n",
    "   \n",
    "\n",
    "#   # Here we plot the contour at a small level, e.g., 0.01.\n",
    "#   # CS = plt.contour(x_range, y_range, psi_values, levels=[0,0.05,0.1,0.2,0.3], colors='red')\n",
    "\n",
    "#   # Define the number of levels for the contour plot\n",
    "#   vmin1, vmax1 = psi_values[:, :, sv_index].min(), psi_values[:, :, sv_index].max()\n",
    "#   num_levels = 200\n",
    "\n",
    "#   levels = np.linspace(0, vmax1, num_levels)\n",
    "  \n",
    "#   # Plot on the provided axis\n",
    "#   if ax is not None:\n",
    "#       cs = ax.contourf(x_values, y_values, psi_values[:, :, sv_index], levels=levels, cmap='viridis')\n",
    "#       ax.set_title(title)\n",
    "#       ax.set_xlabel('x1')\n",
    "#       ax.set_ylabel('x2')\n",
    "#       ax.set_aspect('equal')\n",
    "#       return cs\n",
    "#   else:\n",
    "#     # Create the contour plot using the 'binary' colormap\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "    \n",
    "#     CS = plt.contourf(x_values, y_values, psi_values[:,:,sv_index], levels=levels, cmap = 'viridis')\n",
    "#     cbar = plt.colorbar(CS)\n",
    "#     plt.title(f'Singular value no.{sv_index} of Jacobian \\nwith output layer')\n",
    "#     plt.xlabel('x1')\n",
    "#     plt.ylabel('x2')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# Put the model in evaluation mode.\n",
    "model = model_base\n",
    "model.eval()\n",
    "func = model_to_func(model)  # Add artificial batch dimension which is needed because of batch normalization layer BatchNorm1d and remove it again from the model output.\n",
    "\n",
    "sv_plot(func, sv_index = 0, title = f'Largest SV without output layer')\n",
    "sv_plot(func, sv_index = 1, title = f'Second largest SV of Jacobian without output layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "num_hidden = model.num_hidden\n",
    "\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 2, figsize=(5 * (num_hidden + 2), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 2):\n",
    "    func = model_to_func(model, from_layer=0, to_layer = layer)\n",
    "\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, sv_index = 0, ax = ax, grid_size=100)\n",
    "    # fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min SV\\n layer_in = 0, layer_out = {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, sv_index = 1, ax = ax, grid_size=100)\n",
    "    # fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max SV\\n layer_in = 0, layer_out = {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model in evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 2, figsize=(5 * (num_hidden + 2), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 2):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, sv_index= 0 , ax = ax, grid_size=100)\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max SV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, sv_index=1, ax = ax, grid_size=100)\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min SV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('SV_each_layer.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plots.plots) # Reload the module\n",
    "from plots.plots import plot_singular_values_of_weightmatrix\n",
    "plot_singular_values_of_weightmatrix(model_base, log_scale=False, title = 'Baseline model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 2, figsize=(5 * (num_hidden + 2), 10))  # Adjust figsize if needed\n",
    "\n",
    "x_range = np.linspace(-1, 1, grid_size)\n",
    "y_range = np.linspace(-1, 1, grid_size)\n",
    "\n",
    "for layer in range(num_hidden + 2):\n",
    "    func = lambda inp: model.sub_model(inp, from_layer = layer, to_layer=layer)\n",
    "\n",
    "    # Evaluate psi(x) over the grid.\n",
    "    for i, xv in enumerate(x_range):\n",
    "        for j, yv in enumerate(y_range):\n",
    "            x_point = torch.tensor([xv, yv], dtype=torch.float32)\n",
    "            psi_values[j, i, :] = psi_manual(x_point, func)\n",
    "\n",
    "    # Determine contour levels\n",
    "    vmin1, vmax1 = psi_values[:, :, 1].min(), psi_values[:, :, 1].max()\n",
    "    num_levels_contour = 200\n",
    "    levels1 = np.linspace(0, vmax1, num_levels_contour)\n",
    "\n",
    "    # Plot smallest singular value (index 1) - first row\n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = ax.contourf(x_range, y_range, psi_values[:, :, 1], \n",
    "                     levels=levels1,\n",
    "                     cmap='viridis')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min SV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Determine contour levels\n",
    "    vmin0, vmax0 = psi_values[:, :, 0].min(), psi_values[:, :, 0].max()\n",
    "    num_levels_contour = 200\n",
    "    levels0 = np.linspace(0, vmax0, num_levels_contour)\n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = ax.contourf(x_range, y_range, psi_values[:, :, 0],\n",
    "                     levels=levels0, \n",
    "                     cmap='viridis')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max SV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10 , 5))  # Adjust figsize if needed\n",
    "\n",
    "\n",
    "\n",
    "class TestFunc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestFunc, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.norm(x)**2\n",
    "    \n",
    "    \n",
    "def psi_manual_test(x, func):\n",
    "    \"\"\"\n",
    "    x: a tensor of shape (2,) representing a point in R^2.\n",
    "    model: a function mapping R^2 to R^output_dim.\n",
    "    \n",
    "    Returns:\n",
    "      The smallest singular value of the Jacobian of model at x.\n",
    "    \"\"\"\n",
    "    # Ensure x is a leaf variable with gradient tracking enabled.\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Define a lambda function to ensure accurate input-output mapping\n",
    "    # func = lambda inp: model(inp, output_layer = False)\n",
    "    \n",
    "    # Compute the Jacobian using torch.autograd.functional.jacobian (compatible with Python 3.8)\n",
    "    jacobian = torch.autograd.functional.jacobian(func, x, create_graph=True).unsqueeze(0)\n",
    "    print(f'{jacobian = }')\n",
    "    \n",
    "    # Compute singular values using svdvals (available in PyTorch 1.8, compatible with Python 3.8)\n",
    "    singular_values = torch.svd(jacobian, compute_uv=False)[1]\n",
    "    print(f'{singular_values = }')\n",
    "    \n",
    "   \n",
    "    return singular_values.detach().numpy()\n",
    "\n",
    "test_func = TestFunc()\n",
    "\n",
    "# Evaluate psi(x) over the grid.\n",
    "for i, xv in enumerate(x_range):\n",
    "    for j, yv in enumerate(y_range):\n",
    "        x_point = torch.tensor([xv, yv], dtype=torch.float32)\n",
    "        psi_values[j, i, :] = psi_manual_test(x_point, test_func)\n",
    "        \n",
    "\n",
    "# Determine contour levels\n",
    "vmin1, vmax1 = psi_values[:, :, 1].min(), psi_values[:, :, 1].max()\n",
    "num_levels_contour = 200\n",
    "levels1 = np.linspace(0, vmax1, num_levels_contour)\n",
    "\n",
    "# Plot smallest singular value (index 1) - first row\n",
    "ax = axes[0]\n",
    "cs = ax.contourf(x_range, y_range, psi_values[:, :, 1], \n",
    "                    levels=levels1,\n",
    "                    cmap='viridis')\n",
    "fig.colorbar(cs, ax=ax)\n",
    "ax.set_title(f'Min SV\\n layer {layer}')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "# Determine contour levels\n",
    "vmin0, vmax0 = psi_values[:, :, 0].min(), psi_values[:, :, 0].max()\n",
    "num_levels_contour = 200\n",
    "levels0 = np.linspace(0, vmax0, num_levels_contour)\n",
    "\n",
    "# Plot largest singular value (index 0) - second row\n",
    "ax = axes[1] \n",
    "cs = ax.contourf(x_range, y_range, psi_values[:, :, 0],\n",
    "                    levels=levels0, \n",
    "                    cmap='viridis')\n",
    "fig.colorbar(cs, ax=ax)\n",
    "ax.set_title(f'Max SV\\n layer {layer}')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
