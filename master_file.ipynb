{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master file\n",
    "\n",
    "This file should combine all the other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.colors import LinearSegmentedColormap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "num_hidden = 5 # number of hidden layers. The total network has additionl 2 layers: input to hidden and hidden to output\n",
    "input_dim = 2\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "activation = 'tanh' #'relu' and 'tanh' are supported\n",
    "\n",
    "# Training Params\n",
    "load_file = None\n",
    "cross_entropy = True #True supported with binary classification only, False needs accuracy fix\n",
    "num_epochs = 300\n",
    "\n",
    "subfolder = 'master_file'\n",
    "import os\n",
    "if not os.path.exists(subfolder):\n",
    "    os.makedirs(subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.training\n",
    "from models.training import make_circles_uniform\n",
    "\n",
    "# Generate training data\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = np.random.randint(1000)\n",
    "# seed = 163\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "#footnnote to display on plots to make sure that plots and model/trainign params do not get confused\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "n_points = 2000 #number of points in the dataset\n",
    "\n",
    "inner_radius = 0.5\n",
    "outer_radius = 1\n",
    "buffer = 0.2\n",
    "\n",
    "import importlib\n",
    "importlib.reload(models.training) # Reload the module\n",
    "\n",
    "train_loader, test_loader = make_circles_uniform(output_dim = 1, n_samples = n_points, inner_radius = 0.5, outer_radius = 1.0, buffer = 0.1, cross_entropy=cross_entropy, seed = seed, filename = subfolder + '/circles_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, label in train_loader:\n",
    "    print(input[:5], label[:5])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload models.resnet module after changes without restarting the kernel\n",
    "import importlib\n",
    "import models.resnets\n",
    "import models.training\n",
    "importlib.reload(models.resnets) # Reload the module\n",
    "importlib.reload(models.training) # Reload the module\n",
    "from models.resnets import ResNet\n",
    "from models.training import compute_accuracy, train_model, train_until_threshold, plot_loss_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Constant width 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_param = 0\n",
    "# Train models\n",
    "model_base, acc_base, losses_base = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=skip_param, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_base, title=f\"Base Model Loss Curve\", filename = subfolder + '/ff6hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import plots.plots \n",
    "from plots.plots import plot_decision_boundary, plot_level_sets\n",
    "importlib.reload(plots.plots) # Reload the module\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_base, X_test, y_test, show=True, file_name= subfolder + '/ff6hiddencirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_base, show=True, file_name= subfolder + '/ff6hiddencirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented model: width 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 3\n",
    "num_hidden = 1\n",
    "\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "seed = 288\n",
    "\n",
    "model_aug, acc_aug, losses_aug = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95, seed=seed,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_aug, title=f\"Augmented Model Loss Curve\", filename = subfolder + '/ff6hidden_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "plot_decision_boundary(model_aug, X_test, y_test, show=True, file_name= subfolder + '/ffaugcirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_aug, show=True, file_name= subfolder + '/ffaugcirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_param = 1 # this sets model from feed forward to residual network\n",
    "\n",
    "num_hidden = 6\n",
    "hidden_dim = 2\n",
    "\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "\n",
    "\n",
    "model_res, acc_res, losses_res = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=skip_param, activation=activation,\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_res, title=f\"ResNet Model Loss Curve\", filename = subfolder + '/ff6_res')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_res, X_test, y_test, show=True, file_name= subfolder + '/ff6resnetcirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_res, show=True, file_name= subfolder + '/ff6resnetcirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 10, plotrange=[-2.5,2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import plot_singular_values_of_weightmatrix, plot_EVmod_of_weightmatrix\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "num_epochs = 100\n",
    "\n",
    "models_with_skipparams = {}\n",
    "\n",
    "\n",
    "skip_values = np.linspace(0, 5, 6)  # e.g., [0.0, 0.125, ..., 1.0]\n",
    "# skip_values = [0, 0, 0 , 0 , 0]  # e.g., [0.0, 0.125, ..., 1.0]\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(skip_values) / n_cols))\n",
    "fig1, axes1 = plt.subplots(n_rows, n_cols, figsize=(3.5 * n_cols, 4 * n_rows), facecolor='white', dpi = 900)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.) \n",
    "fig2, axes2 = plt.subplots(n_rows, n_cols, figsize=(3.5 * n_cols, 4 * n_rows), facecolor='white', dpi = 900)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.) \n",
    "\n",
    "# num_epochs = 10\n",
    "for idx, skip in enumerate(skip_values):\n",
    "    print(f\"Training model with skip_param = {skip:.2f}\")\n",
    "    \n",
    "    seed = 14 #10 had complex eigenvalues\n",
    "    print(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # activation = 'tanh'\n",
    "\n",
    "    model = ResNet(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim,\n",
    "                   num_hidden=num_hidden, skip_param=skip, activation=activation)\n",
    "\n",
    "    train_model(model, train_loader, test_loader, epochs = num_epochs, early_stopping = False)\n",
    "    \n",
    "    models_with_skipparams[skip] = model\n",
    "\n",
    "    ax1 = axes1.flatten()[idx]\n",
    "    plot_decision_boundary(model, X_test, y_test, title=f\"Skip: {skip:.2f}\", ax=ax1, show=False, colorbar=False, show_points=False, amount_levels=100)\n",
    "    \n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('')\n",
    "    ax1.axis('tight')\n",
    "    ax1.set_aspect('equal') \n",
    "    \n",
    "    ax2 = axes2.flatten()[idx]\n",
    "    plot_EVmod_of_weightmatrix(model, ax = ax2, log_scale = False, title=f\"Skip: {skip:.2f}\")\n",
    "    \n",
    "    # ax.set_xticks([])\n",
    "    # ax.set_yticks([])\n",
    "    # ax.set_xlabel('')\n",
    "    # ax.set_ylabel('')\n",
    "    # ax.axis('tight')\n",
    "    # ax.set_aspect('equal') \n",
    "    \n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(skip_values), len(axes1.flatten())):\n",
    "    fig1.delaxes(axes1.flatten()[i])\n",
    "\n",
    "# Hide unused subplots for fig2 as well\n",
    "for i in range(len(skip_values), len(axes2.flatten())):\n",
    "    fig2.delaxes(axes2.flatten()[i])\n",
    "    \n",
    "    \n",
    "\n",
    "fig1.suptitle(f\"ResNets with amount layers = {num_hidden + 2} and different weights of shortcut\", fontsize=16)\n",
    "fig2.suptitle(f\"Eigenvalue moduli for different shortcut strengths\", fontsize=16)\n",
    "\n",
    "# Save both figures\n",
    "fig1.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "fig2.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "fig1.savefig(subfolder + '/decision_boundaries_skip_params.png', dpi=900, bbox_inches='tight', facecolor='white')\n",
    "fig2.savefig(subfolder + '/eigenvalue_moduli_skip_params.png', dpi=900, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular value computations of Jacobian and plotting\n",
    "We want to determine singular points in the compact space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid over the input space.\n",
    "grid_size = 200 # Adjust as needed.\n",
    "\n",
    "importlib.reload(plots.plots) # Reload the module\n",
    "from plots.plots import psi_manual, model_to_func, sv_plot\n",
    "        \n",
    "# Put the model in evaluation mode.\n",
    "model = model_base\n",
    "model.eval()\n",
    "func = model_to_func(model)  # Add artificial batch dimension which is needed because of batch normalization layer BatchNorm1d and remove it again from the model output.\n",
    "\n",
    "sv_plot(func, s_index = 0, title = f'Largest SV without output layer')\n",
    "sv_plot(func, v_index = 1, title = f'Second largest SV of Jacobian without output layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "num_hidden = model.num_hidden\n",
    "\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 2, figsize=(5 * (num_hidden + 2), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 2):\n",
    "    func = model_to_func(model, from_layer=0, to_layer = layer)\n",
    "\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index = 0, ax = ax, grid_size=100)\n",
    "    # fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min SV\\n layer_in = 0, layer_out = {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index = 1, ax = ax, grid_size=100)\n",
    "    # fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max SV\\n layer_in = 0, layer_out = {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model in evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100)\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV mod\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100)\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV mod\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(subfolder + '/SV_each_layer.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import sv_plot\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "skip = 0.0\n",
    "model = models_with_skipparams[skip]\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(subfolder + '/EV_each_layer' + str(skip) + '.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import sv_plot\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "skip = 1.0\n",
    "model = models_with_skipparams[skip]\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(subfolder + '/EV_each_layer' + str(skip) + '.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import sv_plot\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "skip = 2.0\n",
    "model = models_with_skipparams[skip]\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(subfolder + '/EV_each_layer' + str(skip) + '.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import make_xor\n",
    "\n",
    "train_loader, test_loader = make_xor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "num_hidden = 6 # number of hidden layers. The total network has additionl 2 layers: input to hidden and hidden to output\n",
    "input_dim = 2\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "activation = 'tanh' #'relu' and 'tanh' are supported\n",
    "\n",
    "# Training Params\n",
    "load_file = None\n",
    "cross_entropy = True #True supported with binary classification only\n",
    "num_epochs = 300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "model_base, acc_base, losses_base = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_base, title=f\"Base Model Loss Curve\", filename = subfolder + '/xor_ff6hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_base, X_test, y_test, show=True, file_name= 'ff6hiddenxor' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_base, show=True, file_name= subfolder + '/ff6hiddenxor_contour' + str(num_hidden), footnote = footnote, amount_levels= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 3\n",
    "num_hidden = 2\n",
    "\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "model_wide, acc_wide, losses_wide = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_wide, title=f\"Wide Model Loss Curve\", filename = subfolder + '/ffxorloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_wide, X_test, y_test, show=True, file_name= 'ffxor' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_wide, show=True, file_name= subfolder + '/ffxor_contour' + str(num_hidden), footnote = footnote, amount_levels= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
