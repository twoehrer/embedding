from pathlib import Path

# Prepare the full notebook content as a string
notebook_code = """
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner vs Outer Circle Neural Network Comparison\\n",
    "This notebook compares two models on the 2D circle classification problem:\\n",
    "- Baseline model with constant width\\n",
    "- Bottleneck model with a width-1 penultimate layer\\n",
    "\\n",
    "Includes early stopping and activation heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\\n",
    "import torch.nn as nn\\n",
    "import torch.nn.functional as F\\n",
    "import matplotlib.pyplot as plt\\n",
    "from sklearn.datasets import make_circles\\n",
    "from sklearn.model_selection import train_test_split\\n",
    "from sklearn.preprocessing import StandardScaler\\n",
    "import numpy as np\\n",
    "\\n",
    "torch.manual_seed(42)\\n",
    "np.random.seed(42)\\n",
    "\\n",
    "# Generate dataset\\n",
    "X, y = make_circles(n_samples=1000, noise=0.05, factor=0.5)\\n",
    "X = StandardScaler().fit_transform(X)\\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\\n",
    ")\\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\\n",
    "y_train = torch.tensor(y_train.reshape(-1, 1), dtype=torch.float32)\\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\\n",
    "y_test = torch.tensor(y_test.reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCircleNetV2(nn.Module):\\n",
    "    def __init__(self, depth=6, width=2, bottleneck=False, activation='tanh'):\\n",
    "        super().__init__()\\n",
    "        act_fn = nn.Tanh if activation == 'tanh' else nn.ReLU\\n",
    "        self.activations = []\\n",
    "        layers = []\\n",
    "        in_features = 2\\n",
    "        for i in range(depth):\\n",
    "            out_features = 1 if bottleneck and i == depth - 2 else width\\n",
    "            layers.append(nn.Linear(in_features, out_features))\\n",
    "            layers.append(nn.BatchNorm1d(out_features))\\n",
    "            layers.append(act_fn())\\n",
    "            in_features = out_features\\n",
    "        layers.append(nn.Linear(in_features, 1))\\n",
    "        self.net = nn.Sequential(*layers)\\n",
    "    def forward(self, x, collect_activations=False):\\n",
    "        self.activations = []\\n",
    "        for layer in self.net[:-1]:\\n",
    "            x = layer(x)\\n",
    "            if collect_activations and isinstance(layer, (nn.Tanh, nn.ReLU)):\\n",
    "                self.activations.append(x.detach().cpu().numpy())\\n",
    "        x = self.net[-1](x)\\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=3000, lr=0.01, patience=300):\\n",
    "    model.train()\\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\\n",
    "    criterion = nn.BCELoss()\\n",
    "    best_acc = 0\\n",
    "    patience_counter = 0\\n",
    "    for epoch in range(epochs):\\n",
    "        y_pred = model(X_train)\\n",
    "        loss = criterion(y_pred, y_train)\\n",
    "        optimizer.zero_grad()\\n",
    "        loss.backward()\\n",
    "        optimizer.step()\\n",
    "        model.eval()\\n",
    "        with torch.no_grad():\\n",
    "            test_preds = model(X_test)\\n",
    "            acc = ((test_preds > 0.5) == y_test).float().mean().item()\\n",
    "        model.train()\\n",
    "        if acc > best_acc:\\n",
    "            best_acc = acc\\n",
    "            patience_counter = 0\\n",
    "        else:\\n",
    "            patience_counter += 1\\n",
    "            if patience_counter >= patience:\\n",
    "                print(f\"Early stopping at epoch {epoch}, best acc: {best_acc:.3f}\")\\n",
    "                break\\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_until_threshold(model_class, X_train, y_train, X_test, y_test,\\n",
    "                          max_retries=10, threshold=0.95, **model_kwargs):\\n",
    "    for attempt in range(1, max_retries + 1):\\n",
    "        model = model_class(**model_kwargs)\\n",
    "        acc = train_model(model, X_train, y_train, X_test, y_test)\\n",
    "        print(f\"[Attempt {attempt}] Accuracy: {acc:.3f}\")\\n",
    "        if acc >= threshold:\\n",
    "            print(f\"✅ Success after {attempt} attempt(s)!\")\\n",
    "            return model, acc\\n",
    "    print(\"❌ Failed to reach threshold.\")\\n",
    "    return model, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_heatmap(model, X):\\n",
    "    model.eval()\\n",
    "    with torch.no_grad():\\n",
    "        _ = model(torch.tensor(X, dtype=torch.float32), collect_activations=True)\\n",
    "    fig, axes = plt.subplots(1, len(model.activations), figsize=(15, 4))\\n",
    "    for i, act in enumerate(model.activations):\\n",
    "        axes[i].imshow(act.T, aspect='auto', cmap='viridis')\\n",
    "        axes[i].set_title(f'Layer {i+1}')\\n",
    "        axes[i].set_xlabel('Samples')\\n",
    "        axes[i].set_ylabel('Activation')\\n",
    "    plt.tight_layout()\\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\\n",
    "    model.eval()\\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\\n",
    "    grid_tensor = torch.tensor(grid, dtype=torch.float32)\\n",
    "    with torch.no_grad():\\n",
    "        preds = model(grid_tensor).numpy().reshape(xx.shape)\\n",
    "    plt.figure(figsize=(6, 6))\\n",
    "    plt.contourf(xx, yy, preds, levels=50, cmap='coolwarm', alpha=0.7)\\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y.squeeze(), cmap='bwr', edgecolors='k')\\n",
    "    plt.title(title)\\n",
    "    plt.xlabel(\"x₁\")\\n",
    "    plt.ylabel(\"x₂\")\\n",
    "    plt.grid(True)\\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both models\\n",
    "model_base, acc_base = train_until_threshold(\\n",
    "    DeepCircleNetV2, X_train, y_train, X_test, y_test,\\n",
    "    max_retries=10, threshold=0.95,\\n",
    "    depth=6, width=2, bottleneck=False, activation='tanh'\\n",
    ")\\n",
    "\\n",
    "model_bottleneck, acc_bottleneck = train_until_threshold(\\n",
    "    DeepCircleNetV2, X_train, y_train, X_test, y_test,\\n",
    "    max_retries=10, threshold=0.95,\\n",
    "    depth=6, width=2, bottleneck=True, activation='tanh'\\n",
    ")\\n",
    "\\n",
    "plot_decision_boundary(model_base, X_test.numpy(), y_test.numpy(), \"Baseline\")\\n",
    "plot_decision_boundary(model_bottleneck, X_test.numpy(), y_test.numpy(), \"Bottleneck\")\\n",
    "\\n",
    "plot_activation_heatmap(model_base, X_test.numpy())\\n",
    "plot_activation_heatmap(model_bottleneck, X_test.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
"""

# Write to file
notebook_path = Path("/mnt/data/circle_nn_comparison.ipynb")
notebook_path.write_text(notebook_code)

notebook_path.name  # Return the file name to show it's ready
