{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# going from ResNet to neural ODE Experiments\n",
    "\n",
    "Let us see what level of discretization leads to nODE restriction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Juptyer magic: For export. Makes the plots size right for the screen \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "seed = np.random.randint(1,200)\n",
    "# seed = 107 #59\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "print(seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "\n",
    "subfolder = 'node_2d'\n",
    "import os\n",
    "if not os.path.exists(subfolder):\n",
    "    os.makedirs(subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet Parameters and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "num_hidden = 5 # number of hidden layers. The total network has additionl 2 layers: input to hidden and hidden to output\n",
    "input_dim = 2\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "skip_param = 1\n",
    "sara_param = 0.5\n",
    "activation = 'tanh' #'relu' and 'tanh' are supported\n",
    "\n",
    "# Training Params\n",
    "load_file = None\n",
    "cross_entropy = True #True supported with binary classification only\n",
    "num_epochs = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.training\n",
    "from models.training import make_circles_uniform\n",
    "\n",
    "\n",
    "\n",
    "# Generate training data\n",
    "n_points = 4000 #number of points in the dataset\n",
    "batch_size = 100\n",
    "\n",
    "inner_radius = 0.5\n",
    "outer_radius = 1\n",
    "buffer = 0.2\n",
    "\n",
    "plotrange = [-2.5,2.5]\n",
    "\n",
    "import importlib\n",
    "importlib.reload(models.training) # Reload the module\n",
    "\n",
    "train_loader, test_loader = make_circles_uniform(output_dim = output_dim, n_samples = n_points, inner_radius = inner_radius, outer_radius = outer_radius, buffer = buffer, cross_entropy = cross_entropy, batch_size = batch_size, seed = seed, filename = subfolder + '/circles_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet case\n",
    "\n",
    "trying to establish a ResNet case that is stable under initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload models.resnet module after changes without restarting the kernel\n",
    "import importlib\n",
    "import models.resnets\n",
    "import models.training\n",
    "importlib.reload(models.resnets) # Reload the module\n",
    "importlib.reload(models.training) # Reload the module\n",
    "from models.resnets import ResNet\n",
    "from models.training import compute_accuracy, train_model, train_until_threshold, plot_loss_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots \n",
    "from plots.plots import plot_decision_boundary, plot_level_sets\n",
    "importlib.reload(plots.plots) # Reload the module\n",
    "\n",
    "activation = 'tanh'\n",
    "batchnorm = False\n",
    "\n",
    "model_res, acc_res, losses_res = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95, early_stopping = False,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=skip_param, sara_param = sara_param, activation=activation, batchnorm = batchnorm\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_res, title=f\"ResNet Model Loss Curve\", filename = subfolder + '/ff6_res')\n",
    "\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_res, X_test, y_test, show=True, file_name= subfolder + '/ff6hiddencirc' + str(num_hidden), footnote = footnote, amount_levels= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    params = list(model_res.parameters())\n",
    "    print(params)\n",
    "    W0 = params[0]   # 0th weight tensor\n",
    "    b0 = params[1]   # 1st is usually the corresponding bias\n",
    "    print(W0)\n",
    "\n",
    "    # # Build a diagonal mask matching W0's shape (works for rectangular too)\n",
    "    eye = torch.eye(W0.size(0), W0.size(1), device=W0.device, dtype=W0.dtype)\n",
    "    \n",
    "    print(eye)\n",
    "    # # Zero out off-diagonals: keep current diag values\n",
    "    W0.mul_(eye)\n",
    "    print(W0)\n",
    "\n",
    "    # # Or: set a specific diagonal value (e.g., 1.0)\n",
    "    # # W0.zero_()\n",
    "    # # W0.add_(eye)  # diagonal = 1\n",
    "\n",
    "    # # Zero the bias if desired\n",
    "    # b0.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_level_sets(model_res, show=True, file_name= subfolder + '/ff6hiddencirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 20, plotrange= [-2.5,2.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nODE Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Model Params\n",
    "#Import of the model dynamics that describe the neural ODE\n",
    "#The dynamics are based on the torchdiffeq package, that implements ODE solvers in the pytorch setting\n",
    "from models.neural_odes import NeuralODEvar\n",
    "\n",
    "#for neural ODE based networks the network width is constant. In this example the input is 2 dimensional\n",
    "hidden_dim, data_dim = 2, 2\n",
    "output_dim = 1\n",
    "\n",
    "#T is the end time of the neural ODE evolution, time_steps are the amount of discretization steps for the ODE solver\n",
    "T, time_steps = 5, 5 #\n",
    "step_size = T/time_steps\n",
    "num_params = 5 #the number of distinct parameters present in the interval. they are spread equidistant over the interval [0, T].\n",
    "\n",
    "layers_hidden = 0 #the amount of layers in the vector field (these layers do not correspond to time discretization but to the expressivity of the vector field)\n",
    "\n",
    "non_linearity = 'tanh' #'relu' #\n",
    "architecture = 'inside' #outside\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training Params\n",
    "cross_entropy = True #True supported with binary classification only\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import doublebackTrainer\n",
    "\n",
    "seed = np.random.randint(1,200)\n",
    "print(seed)\n",
    "# seed = 16\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "node = NeuralODEvar(device, data_dim, hidden_dim, output_dim = output_dim, non_linearity=non_linearity, \n",
    "                    architecture=architecture, T=T, time_steps=time_steps, num_params = num_params, layers_hidden = layers_hidden, cross_entropy=cross_entropy)\n",
    "\n",
    "\n",
    "optimizer_node = torch.optim.Adam(node.parameters(), lr=1e-3) \n",
    "trainer_node = doublebackTrainer(node, optimizer_node, device, cross_entropy=cross_entropy) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.plots import classification_levelsets\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "\n",
    "num_cycles = 3\n",
    "epochs_cycle = int(300/3)\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    trainer_node.train(train_loader, epochs_cycle)\n",
    "    \n",
    "    fig_name_base = os.path.join(subfolder, 'levelsets' + str(i))\n",
    "    classification_levelsets(node, fig_name_base, footnote = footnote, plotlim= [-2,2])\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    fig_name_base = os.path.join(subfolder, 'levelsets' + str(i))\n",
    "    img = Image(filename = fig_name_base + '.png', width = 400)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots\n",
    "importlib.reload(plots.plots) # Reload the module to ensure the latest changes are applied\n",
    "\n",
    "from plots.plots import classification_levelsets\n",
    "from IPython.display import Image\n",
    "\n",
    "footnote = f'{num_epochs = }, {cross_entropy = }, {num_params = },\\n {time_steps = }, {output_dim = }, {hidden_dim = }, {seed = }'\n",
    "        \n",
    "fig_name_base = os.path.join(subfolder, 'levelsets')\n",
    "classification_levelsets(node, fig_name_base, footnote = footnote, plotlim= [-2,2])\n",
    "img1 = Image(filename = fig_name_base + '.png', width = 400)\n",
    "display(img1)\n",
    "plt.plot(trainer_node.histories['epoch_loss_history'])\n",
    "plt.xlim(0, len(trainer_node.histories['epoch_loss_history']) - 1)\n",
    "plt.ylim(0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reload models.resnet module after changes without restarting the kernel\n",
    "import importlib\n",
    "import models.resnets\n",
    "import models.training\n",
    "importlib.reload(models.resnets) # Reload the module\n",
    "importlib.reload(models.training) # Reload the module\n",
    "from models.resnets import ResNet\n",
    "from models.training import compute_accuracy, train_model, train_until_threshold, plot_loss_curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant width 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train models\n",
    "model_base, acc_base, losses_base = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_base, title=f\"Base Model Loss Curve\", filename = 'ff6hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import plots.plots \n",
    "from plots.plots import plot_decision_boundary, plot_level_sets\n",
    "importlib.reload(plots.plots) # Reload the module\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_base, X_test, y_test, show=True, file_name= 'ff6hiddencirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_base, show=True, file_name= 'ff6hiddencirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 20, plotrange= plotrange)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented model: width 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 3\n",
    "num_hidden = 1\n",
    "\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "seed = 288\n",
    "\n",
    "model_aug, acc_aug, losses_aug = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95, seed=seed,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_aug, title=f\"Augmented Model Loss Curve\", filename = 'ff6hidden_aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "plot_decision_boundary(model_aug, X_test, y_test, show=True, file_name= 'ffaugcirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_aug, show=True, file_name= 'ffaugcirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_param = 1 # this sets model from feed forward to residual network\n",
    "\n",
    "num_hidden = 6\n",
    "hidden_dim = 2\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "model_res, acc_res, losses_res = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=skip_param, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_res, title=f\"ResNet Model Loss Curve\", filename = 'ff6_res')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_res, X_test, y_test, show=True, file_name= 'ff6resnetcirc' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_res, show=True, file_name= 'ff6resnetcirc_contour' + str(num_hidden), footnote = footnote, amount_levels= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_test = {}\n",
    "\n",
    "for i in range(3):\n",
    "    model = ResNet(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim,\n",
    "                   num_hidden=num_hidden, skip_param=skip, activation=activation)\n",
    "    \n",
    "    models_test[i] = model\n",
    "    \n",
    "    \n",
    "\n",
    "models_test[0].skip_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib; import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import plot_singular_values_of_weightmatrix, plot_EVmod_of_weightmatrix\n",
    "\n",
    "X_test, y_test = next(iter(test_loader))\n",
    "num_epochs = 100\n",
    "\n",
    "models_with_skipparams = {}\n",
    "\n",
    "\n",
    "skip_values = np.linspace(0, 5, 6)  # e.g., [0.0, 0.125, ..., 1.0]\n",
    "# skip_values = [0, 0, 0 , 0 , 0]  # e.g., [0.0, 0.125, ..., 1.0]\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(len(skip_values) / n_cols))\n",
    "fig1, axes1 = plt.subplots(n_rows, n_cols, figsize=(3.5 * n_cols, 4 * n_rows), facecolor='white', dpi = 900)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.) \n",
    "fig2, axes2 = plt.subplots(n_rows, n_cols, figsize=(3.5 * n_cols, 4 * n_rows), facecolor='white', dpi = 900)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.) \n",
    "\n",
    "# num_epochs = 10\n",
    "for idx, skip in enumerate(skip_values):\n",
    "    print(f\"Training model with skip_param = {skip:.2f}\")\n",
    "    \n",
    "    seed = 14 #10 had complex eigenvalues\n",
    "    print(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # activation = 'tanh'\n",
    "\n",
    "    model = ResNet(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim,\n",
    "                   num_hidden=num_hidden, skip_param=skip, activation=activation)\n",
    "\n",
    "    train_model(model, train_loader, test_loader, epochs=num_epochs, early_stopping=False)\n",
    "    \n",
    "    models_with_skipparams[skip] = model\n",
    "\n",
    "    ax1 = axes1.flatten()[idx]\n",
    "    plot_decision_boundary(model, X_test, y_test, title=f\"Skip: {skip:.2f}\", ax=ax1, show=False, colorbar=False, show_points=False, amount_levels=100)\n",
    "    \n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_ylabel('')\n",
    "    ax1.axis('tight')\n",
    "    ax1.set_aspect('equal') \n",
    "    \n",
    "    ax2 = axes2.flatten()[idx]\n",
    "    plot_EVmod_of_weightmatrix(model, ax = ax2, log_scale = False, title=f\"Skip: {skip:.2f}\")\n",
    "    \n",
    "    # ax.set_xticks([])\n",
    "    # ax.set_yticks([])\n",
    "    # ax.set_xlabel('')\n",
    "    # ax.set_ylabel('')\n",
    "    # ax.axis('tight')\n",
    "    # ax.set_aspect('equal') \n",
    "    \n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(skip_values), len(axes1.flatten())):\n",
    "    fig1.delaxes(axes1.flatten()[i])\n",
    "\n",
    "# Hide unused subplots for fig2 as well\n",
    "for i in range(len(skip_values), len(axes2.flatten())):\n",
    "    fig2.delaxes(axes2.flatten()[i])\n",
    "    \n",
    "    \n",
    "\n",
    "fig1.suptitle(f\"ResNets with amount layers = {num_hidden + 2} and different weights of shortcut\", fontsize=16)\n",
    "fig2.suptitle(f\"Eigenvalue moduli for different shortcut strengths\", fontsize=16)\n",
    "\n",
    "# Save both figures\n",
    "fig1.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "fig2.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "fig1.savefig('decision_boundaries_skip_params.png', dpi=900, bbox_inches='tight', facecolor='white')\n",
    "fig2.savefig('eigenvalue_moduli_skip_params.png', dpi=900, bbox_inches='tight', facecolor='white')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular value computations of Jacobian and plotting\n",
    "We want to determine singular points in the compact space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid over the input space.\n",
    "grid_size = 200 # Adjust as needed.\n",
    "\n",
    "importlib.reload(plots.plots) # Reload the module\n",
    "from plots.plots import psi_manual, model_to_func, sv_plot\n",
    "        \n",
    "# Put the model in evaluation mode.\n",
    "model = model_base\n",
    "model.eval()\n",
    "func = model_to_func(model)  # Add artificial batch dimension which is needed because of batch normalization layer BatchNorm1d and remove it again from the model output.\n",
    "\n",
    "sv_plot(func, s_index = 0, title = f'Largest SV without output layer')\n",
    "sv_plot(func, v_index = 1, title = f'Second largest SV of Jacobian without output layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "num_hidden = model.num_hidden\n",
    "\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 2, figsize=(5 * (num_hidden + 2), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 2):\n",
    "    func = model_to_func(model, from_layer=0, to_layer = layer)\n",
    "\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index = 0, ax = ax, grid_size=100)\n",
    "    # fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min SV\\n layer_in = 0, layer_out = {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index = 1, ax = ax, grid_size=100)\n",
    "    # fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max SV\\n layer_in = 0, layer_out = {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model in evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100)\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV mod\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100)\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV mod\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('SV_each_layer.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import sv_plot\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "skip = 0.0\n",
    "model = models_with_skipparams[skip]\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('EV_each_layer' + str(skip) + '.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import sv_plot\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "skip = 1.0\n",
    "model = models_with_skipparams[skip]\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('EV_each_layer' + str(skip) + '.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plots.plots; importlib.reload(plots.plots)\n",
    "from plots.plots import sv_plot\n",
    "\n",
    "# Put the model in evaluation mode.\n",
    "skip = 2.0\n",
    "model = models_with_skipparams[skip]\n",
    "model.eval()\n",
    "\n",
    "# Prepare figure and axes\n",
    "fig, axes = plt.subplots(2, num_hidden + 1, figsize=(5 * (num_hidden + 1), 10))  # Adjust figsize if needed\n",
    "\n",
    "for layer in range(num_hidden + 1):\n",
    "    func = model_to_func(model, from_layer=layer, to_layer = layer)\n",
    "    \n",
    "    ax = axes[0, layer] if num_hidden > 1 else axes[0]\n",
    "    cs = sv_plot(func, v_index= 0 , ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Max EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "\n",
    "    # Plot largest singular value (index 0) - second row\n",
    "    ax = axes[1, layer] if num_hidden > 1 else axes[1]\n",
    "    cs = sv_plot(func, v_index=1, ax = ax, grid_size=100, output_type='eigmods')\n",
    "    fig.colorbar(cs, ax=ax)\n",
    "    ax.set_title(f'Min EV\\n layer {layer}')\n",
    "    ax.set_xlabel('x1')\n",
    "    ax.set_ylabel('x2')\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('EV_each_layer' + str(skip) + '.png', dpi=600, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.training import make_xor\n",
    "\n",
    "train_loader, test_loader = make_xor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "num_hidden = 6 # number of hidden layers. The total network has additionl 2 layers: input to hidden and hidden to output\n",
    "input_dim = 2\n",
    "hidden_dim = 2\n",
    "output_dim = 1\n",
    "activation = 'tanh' #'relu' and 'tanh' are supported\n",
    "\n",
    "# Training Params\n",
    "load_file = None\n",
    "cross_entropy = True #True supported with binary classification only\n",
    "num_epochs = 300\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "model_base, acc_base, losses_base = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_base, title=f\"Base Model Loss Curve\", filename = 'xor_ff6hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_base, X_test, y_test, show=True, file_name= 'ff6hiddenxor' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_base, show=True, file_name= 'ff6hiddenxor_contour' + str(num_hidden), footnote = footnote, amount_levels= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 3\n",
    "num_hidden = 2\n",
    "\n",
    "footnote = f'num_hidden={num_hidden}, hidden_dim={hidden_dim}, output_dim={output_dim}, act={activation}, seed={seed}, ce={cross_entropy}'\n",
    "\n",
    "model_wide, acc_wide, losses_wide = train_until_threshold(ResNet,\n",
    "    train_loader, test_loader,\n",
    "    load_file = load_file, max_retries=5, threshold=0.95,\n",
    "    input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_hidden=num_hidden, skip_param=0, activation=activation\n",
    ")\n",
    "\n",
    "plot_loss_curve(losses_wide, title=f\"Wide Model Loss Curve\", filename = 'ffxorloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(test_loader))\n",
    "plot_decision_boundary(model_wide, X_test, y_test, show=True, file_name= 'ffxor' + str(num_hidden), footnote = footnote, amount_levels= 100)\n",
    "plot_level_sets(model_wide, show=True, file_name= 'ffxor_contour' + str(num_hidden), footnote = footnote, amount_levels= 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralODE",
   "language": "python",
   "name": "neuralode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
